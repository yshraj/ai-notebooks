{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3XPnaheoq56"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "4fe61x1cBUER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b188dfb0-58f8-43d0-a684-986e2c154d21"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d0bf281-793f-4eed-89c3-781c8efc0dd3"
      },
      "outputs": [],
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"/content/new_articles/\", glob = \"./*.txt\", loader_cls= TextLoader)\n",
        "document=loader.load()"
      ],
      "metadata": {
        "id": "RY7zroS-AaSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Split documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "_nV0aa8ZALCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFzpFqn1orgm"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\"  # Replace with your actual key"
      ],
      "metadata": {
        "id": "3-zuk5tD7CJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4fgFnnupI0P"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"tiiuae/falcon-7b-instruct\"  # or try smaller like \"tiiuae/falcon-7b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512, temperature=0.7)\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "persist_directory = \"db\"\n",
        "vectordb = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=persist_directory)\n",
        "vectordb.persist()\n",
        "\n",
        "# Reload if needed later\n",
        "# vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "fWFSpTj9BRBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "r7JrtmSTBgpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "JkUvWj2j_i1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ee9GT6spY1S"
      },
      "outputs": [],
      "source": [
        "query = \"How much money did Microsoft raise?\"\n",
        "response = qa_chain(query)\n",
        "\n",
        "# Output result with source\n",
        "def process_llm_response(res):\n",
        "    print(\"Answer:\", res['result'])\n",
        "    print(\"\\nSources:\")\n",
        "    for src in res[\"source_documents\"]:\n",
        "        print(src.metadata[\"source\"])\n",
        "\n",
        "process_llm_response(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KEKQAlOuB9NG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}